{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aad2b3e-5b0e-4986-8863-56b87ac86ce4",
   "metadata": {},
   "source": [
    "# Bayesian A/B Test\n",
    "\n",
    "Autor: Luca Honegger, lh@sinnhaft.ch\n",
    "\n",
    "Quelle: Dies ist eine Python-Portierung der UXtoolbox in R von Mohsen Rafiei, https://github.com/mohsen-rafiei/UXtoolbox\n",
    "\n",
    "## 🧠 Was macht diese Funktion?\n",
    "\n",
    "Die Funktion `bayesian_ab_test()` führt einen **Bayesschen A/B-Test** durch.\n",
    "Sie vergleicht zwei Gruppen (z. B. Variante A vs. Variante B) basierend auf Erfolgen und Gesamtversuchen.\n",
    "\n",
    "### 🔍 Was wird berechnet?\n",
    "\n",
    "* Wie wahrscheinlich ist es, dass **A besser abschneidet als B** – und umgekehrt\n",
    "* Wie hoch ist die **erwartete Erfolgsrate** für A und B\n",
    "* Wie gross ist der **wahrscheinliche Unterschied** (Credible Interval)\n",
    "\n",
    "Dabei wird nicht nur ein einfacher Mittelwert verglichen, sondern **Unsicherheit mit einbezogen** – das ist der Vorteil von Bayesian Statistics.\n",
    "\n",
    "## 🧪 Beispiel aus dem Business-Alltag\n",
    "\n",
    "Stell dir vor, du testest zwei Versionen einer Landingpage:\n",
    "\n",
    "* **Variante A:** 65 Conversions bei 90 Besuchern\n",
    "* **Variante B:** 72 Conversions bei 110 Besuchern (z. B. aus einer kleinen gezielten Kampagne)\n",
    "\n",
    "Mit `bayesian_ab_test([65, 72], [90, 100])` bekommst du:\n",
    "\n",
    "* Wie wahrscheinlich es ist, dass **Variante A oder B besser ist**\n",
    "* Und wie gross der Unterschied **realistisch** sein kann\n",
    "\n",
    "Das hilft dir bei **datenbasierten Entscheidungen**, auch wenn die Stichprobe klein oder ungleich verteilt ist – typisches Szenario z. B. bei MVP-Tests, Marketing-Kampagnen oder Produktexperimenten.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d91b6352-37a0-4768-8ce7-4d7fb73e1ce5",
   "metadata": {},
   "source": [
    "## `bayesian_ab_test`\n",
    "mit SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93acc629-00d7-40ae-9eee-2a6d0f215a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import beta\n",
    "\n",
    "def bayesian_ab_test(successes, trials, ci=0.95, n_samples=10000):\n",
    "    \"\"\"\n",
    "    Führt einen bayesschen A/B-Test durch mit Beta-Verteilungen als Posterior.\n",
    "\n",
    "    Parameter:\n",
    "    - successes: Liste mit Erfolgen für A und B (z. B. [10, 20])\n",
    "    - trials: Liste mit Versuchen für A und B (z. B. [800, 25])\n",
    "    - n_samples: Anzahl der Monte-Carlo-Samples\n",
    "    - ci: Konfidenzintervall (Credible Interval), z. B. 0.95 für 95 %\n",
    "\n",
    "    Rückgabe:\n",
    "    - Dictionary mit:\n",
    "        - mittlere Erfolgswahrscheinlichkeiten\n",
    "        - Wahrscheinlichkeit, dass A besser ist als B (und umgekehrt)\n",
    "        - Credible Interval der Differenz A − B\n",
    "    \"\"\"\n",
    "    # Posterior-Parameter berechnen\n",
    "    alpha_a = successes[0] + 1\n",
    "    beta_a = trials[0] - successes[0] + 1\n",
    "    alpha_b = successes[1] + 1\n",
    "    beta_b = trials[1] - successes[1] + 1\n",
    "\n",
    "    # Stichproben aus den Posterior-Verteilungen\n",
    "    samples_a = beta.rvs(alpha_a, beta_a, size=n_samples)\n",
    "    samples_b = beta.rvs(alpha_b, beta_b, size=n_samples)\n",
    "\n",
    "    # Wahrscheinlichkeiten berechnen\n",
    "    prob_a_better = np.mean(samples_a > samples_b)\n",
    "    prob_b_better = np.mean(samples_b > samples_a)\n",
    "\n",
    "    # Differenz und Credible Interval\n",
    "    diff = samples_a - samples_b\n",
    "    lower = float(np.percentile(diff, (1 - ci) / 2 * 100))\n",
    "    upper = float(np.percentile(diff, (1 + ci) / 2 * 100))\n",
    "\n",
    "    return {\n",
    "        \"Probability_A\": np.mean(samples_a),\n",
    "        \"Probability_B\": np.mean(samples_b),\n",
    "        \"Probability_A_Better\": prob_a_better,\n",
    "        \"Probability_B_Better\": prob_b_better,\n",
    "        \"Credible_Interval\": (lower, upper)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffbe4d4a-7b6e-490a-90de-eeb10f536723",
   "metadata": {},
   "source": [
    "## Anwendungsbeispiel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4584a7ef-f123-4a49-b897-b4d1491dbdb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wahrscheinlichkeit, dass A erfolgreich ist: 0.717\n",
      "Wahrscheinlichkeit, dass B erfolgreich ist: 0.652\n",
      "Wahrscheinlichkeit, dass A besser ist als B: 0.845\n",
      "Wahrscheinlichkeit, dass B besser ist als A: 0.155\n",
      "Credible Interval (95.0)%: -0.06, 0.19\n"
     ]
    }
   ],
   "source": [
    "# Beispiel\n",
    "# A = 65 Erfolge, 90 Versuche\n",
    "# B = 72 Erfolge, 110 Versuche\n",
    "# Credible Interval = 95%\n",
    "\n",
    "ci = 0.95\n",
    "result = bayesian_ab_test([65, 72], [90, 110], ci)\n",
    "\n",
    "print(f\"Wahrscheinlichkeit, dass A erfolgreich ist: {result['Probability_A']:.3f}\")\n",
    "print(f\"Wahrscheinlichkeit, dass B erfolgreich ist: {result['Probability_B']:.3f}\")\n",
    "\n",
    "print(f\"Wahrscheinlichkeit, dass A besser ist als B: {result['Probability_A_Better']:.3f}\")\n",
    "print(f\"Wahrscheinlichkeit, dass B besser ist als A: {result['Probability_B_Better']:.3f}\")\n",
    "\n",
    "print(f\"Credible Interval ({ci*100})%: {result['Credible_Interval'][0]:.2f}, {result['Credible_Interval'][1]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a79755-d647-4baa-89fe-902957d178fc",
   "metadata": {},
   "source": [
    "### 📊 Erklärung und Interpretation\n",
    "\n",
    "\n",
    "#### Kontext der Analyse\n",
    "\n",
    "* Variante **A**: 65 Erfolge bei 90 Versuchen → Erfolgsrate ≈ 72 %\n",
    "* Variante **B**: 72 Erfolge bei 110 Versuchen → Erfolgsrate ≈ 65 %\n",
    "\n",
    "Du möchtest wissen: **Ist A besser als B?**\n",
    "\n",
    "\n",
    "#### Was sagt das Credible Interval?\n",
    "\n",
    "```\n",
    "Credible Interval (95%): –0.06, 0.19\n",
    "```\n",
    "\n",
    "➡️ Das bedeutet:\n",
    "Mit **95 % Wahrscheinlichkeit** liegt der wahre Unterschied der Erfolgsraten zwischen **A und B** irgendwo zwischen **–6 Prozentpunkten und +19 Prozentpunkten**.\n",
    "\n",
    "* Ein **positiver Wert** würde bedeuten: A ist besser als B\n",
    "* Ein **negativer Wert** würde bedeuten: B ist besser als A\n",
    "\n",
    "\n",
    "#### Interpretation im Beispiel\n",
    "\n",
    "* Der Wert **0** liegt **innerhalb** des Intervalls → Wir können **nicht sicher** sagen, dass A **wirklich besser** ist.\n",
    "* Die Wahrscheinlichkeit, dass A besser ist als B liegt zwar bei **84,8 %**, aber es gibt noch **Restunsicherheit**, da das Intervall auch **negative Unterschiede** zulässt.\n",
    "\n",
    "\n",
    "#### 📌 Fazit\n",
    "\n",
    "> A **ist wahrscheinlich besser**, aber der Unterschied ist **nicht 100 % sicher**.\n",
    "> Das **Credible Interval zeigt, wie gross der Unterschied vermutlich ist** – inklusive Unsicherheit.\n",
    "\n",
    "Das ist eine zentrale Stärke der **Bayesschen Analyse**: Sie zeigt dir **nicht nur, was wahrscheinlich ist**, sondern **wie sicher** du dir sein kannst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18dae7-3d1f-404a-9a71-2a6a0c47b933",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
